{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "603b02e3",
   "metadata": {},
   "source": [
    "# Proposal for Group 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c5aae1",
   "metadata": {},
   "source": [
    "## 1. Data\n",
    "### 1.1 data source\n",
    "Our purpose for this project is to classify animal images into 15 categories through CNN model. Dataset comes from Kaggle.com.All the images present in TF records format have already been resized to 256 x 256 pixels and normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c44ad80",
   "metadata": {},
   "source": [
    "### 1.2 data description"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b1fecc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T02:29:06.111128Z",
     "start_time": "2024-11-05T02:29:02.188470Z"
    }
   },
   "source": [
    "import zipfile\n",
    "import io\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "zip_path = \"archive.zip\"\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zebra_files = [file for file in zip_ref.namelist() if file.startswith(\"Validation Data/Validation Data/Zebra/\") and file.endswith(\".jpeg\")]\n",
    "    if zebra_files:\n",
    "        first_image_file = zebra_files[0]\n",
    "        print(f\"Viewing the first image file: {first_image_file}\")\n",
    "        with zip_ref.open(first_image_file) as image_file:\n",
    "            image = Image.open(io.BytesIO(image_file.read()))\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')  # Hide the axes\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No files found in the specified folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6185079",
   "metadata": {},
   "source": [
    "## 2. descriptions of the variables\n",
    "Input Image(RGB graphs with 3 channels):\n",
    "Our input will be 3 dimensional integer matrices with index as (Height X Width X 3) with range of channel to be 0-255.\n",
    "\n",
    "Label:\n",
    "Once image is put into the model, a String of predicted label will be added to it. This helps us match the image with its category. \n",
    "\n",
    "Class Names:\n",
    "We set up a list of String to describe the categories we would like to classify into. An 1 to 1 conressponing relation between Class Names and Labels should be expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ef87fd",
   "metadata": {},
   "source": [
    "## 3. statistical methods\n",
    "The statistical methods we plan to use is as follows, \n",
    "\n",
    "Pooling: Each small section of the image can be summrised into one larger section with critical features included.\n",
    "\n",
    "Data Augmentation:We apply random transformation,including rotation, flipping and zooming etc., to increase the diversity of training data.\n",
    "\n",
    "3.3 Regularization: In the fully connected layers, we apply L1 and L2 penalties to the loss function to force our model minimise both cross entropy and regularised loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d635cd41",
   "metadata": {},
   "source": [
    "## 4. computational steps\n",
    "### 4.1 Create Parallel Computing Structure\n",
    "We allocate the smaller batches of images to different GPUs for simultaneous computation, through applying DistributedDataParallel to wrapper the model.Proper DistributedSampler will be used to distribute different train data and layers of CNN mdodels to GPUs.\n",
    "### 4.2, Work on GPU\n",
    "We use the following code to ask GPU working on computating process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7cb7f8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T02:29:06.115776Z",
     "start_time": "2024-11-05T02:29:06.112134Z"
    }
   },
   "outputs": [],
   "source": [
    "#request_cpus = 4          \n",
    "#request_gpus = 1          \n",
    "#request_memory = 16GB      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69be867",
   "metadata": {},
   "source": [
    "### 4.3 Model Backpropagation\n",
    "We will minimise Cross Entropy as our loss function,and use Adam to update weights in the network. We also use DistributedDataParallel to synchronize all gradients of GPUs. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311gpu",
   "language": "python",
   "name": "python311gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
